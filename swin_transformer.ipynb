{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swin Transformer\n",
    "In this notebook, we use transfer learning to train a classification head on top of a pretrained Swin Transformer backbone over 5 folds. Through public discussions, it was found that Swin Transformers perform better than normal Convolutional Neural Networks for this competition. Public discussions further discovered that even though the initial problem statement is a regression problem, converting this regression problem into a classification problem yields better results. Therefore, the model is trained using the binary cross entropy (BCE) loss rather than the mean squared error (MSE) loss. We then convert the predictions back to the initial value range from 0 to 100 by applying the sigmoid function and multiplying by 100. We are building off of top-scoring public notebooks and discussions. Important custom modifications are noted in comments. This notebook is intended to be run on Kaggle with GPU enabled and with the necessary packages and datasets in the working directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-28T01:58:03.613767Z",
     "iopub.status.busy": "2021-11-28T01:58:03.613521Z",
     "iopub.status.idle": "2021-11-28T01:58:12.194551Z",
     "shell.execute_reply": "2021-11-28T01:58:12.193759Z",
     "shell.execute_reply.started": "2021-11-28T01:58:03.613696Z"
    },
    "papermill": {
     "duration": 0.092857,
     "end_time": "2021-11-26T04:48:12.173732",
     "exception": false,
     "start_time": "2021-11-26T04:48:12.080875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add tez and timm libraries to Kaggle\n",
    "import sys\n",
    "sys.path.append(\"../input/tez-lib/\")\n",
    "sys.path.append(\"../input/timmmaster/\")\n",
    "\n",
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Image manipulation\n",
    "import cv2\n",
    "\n",
    "# Main neural network library\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "# Easier PyTorch development\n",
    "import tez\n",
    "from tez.callbacks import EarlyStopping\n",
    "\n",
    "# Image augmentations\n",
    "import albumentations\n",
    "\n",
    "# Swin Transformer backbone\n",
    "import timm\n",
    "\n",
    "# Calculate MSE\n",
    "from sklearn import metrics\n",
    "\n",
    "# Progress display\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-28T01:58:12.198106Z",
     "iopub.status.busy": "2021-11-28T01:58:12.197626Z",
     "iopub.status.idle": "2021-11-28T01:58:12.203180Z",
     "shell.execute_reply": "2021-11-28T01:58:12.200733Z",
     "shell.execute_reply.started": "2021-11-28T01:58:12.198076Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fold to train\n",
    "FOLD = 0\n",
    "\n",
    "# Input image size\n",
    "IMAGE_SIZE = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-28T01:58:12.204971Z",
     "iopub.status.busy": "2021-11-28T01:58:12.204715Z",
     "iopub.status.idle": "2021-11-28T01:58:12.211381Z",
     "shell.execute_reply": "2021-11-28T01:58:12.210535Z",
     "shell.execute_reply.started": "2021-11-28T01:58:12.204940Z"
    },
    "papermill": {
     "duration": 0.014111,
     "end_time": "2021-11-26T04:48:20.325803",
     "exception": false,
     "start_time": "2021-11-26T04:48:20.311692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To denormalize predictions\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-28T01:58:12.213853Z",
     "iopub.status.busy": "2021-11-28T01:58:12.213528Z",
     "iopub.status.idle": "2021-11-28T01:58:12.224177Z",
     "shell.execute_reply": "2021-11-28T01:58:12.223475Z",
     "shell.execute_reply.started": "2021-11-28T01:58:12.213820Z"
    },
    "papermill": {
     "duration": 0.019498,
     "end_time": "2021-11-26T04:48:20.353386",
     "exception": false,
     "start_time": "2021-11-26T04:48:20.333888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset:\n",
    "    def __init__(self, image_paths, dense_features, targets, augmentations):\n",
    "        self.image_paths = image_paths\n",
    "        self.dense_features = dense_features\n",
    "        self.targets = targets\n",
    "        self.augmentations = augmentations\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        # Read image and convert BGR to RGB\n",
    "        image = cv2.imread(self.image_paths[item])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Augmentations\n",
    "        if self.augmentations is not None:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "            \n",
    "        # OpenCV is (height, width, channel)\n",
    "        # PyTorch wants (channel, height, width)\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        \n",
    "        # Photo metadata\n",
    "        features = self.dense_features[item, :]\n",
    "        \n",
    "        # Important: divide by 100 to normalize targets for BCE loss\n",
    "        targets = self.targets[item] / 100.0\n",
    "        \n",
    "        return {\n",
    "            \"image\": torch.tensor(image, dtype=torch.float),\n",
    "            \"features\": torch.tensor(features, dtype=torch.float),\n",
    "            \"targets\": torch.tensor(targets, dtype=torch.float),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-28T01:58:12.225801Z",
     "iopub.status.busy": "2021-11-28T01:58:12.225534Z",
     "iopub.status.idle": "2021-11-28T01:58:12.239790Z",
     "shell.execute_reply": "2021-11-28T01:58:12.239164Z",
     "shell.execute_reply.started": "2021-11-28T01:58:12.225768Z"
    },
    "papermill": {
     "duration": 0.021467,
     "end_time": "2021-11-26T04:48:20.382981",
     "exception": false,
     "start_time": "2021-11-26T04:48:20.361514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomModel(tez.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Swin Transformer backbone\n",
    "        self.model = timm.create_model(\"swin_large_patch4_window12_384\", pretrained=True, in_chans=3)\n",
    "        \n",
    "        # Classification head\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, 128)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.Linear(140, 64)\n",
    "        \n",
    "        # Important: add ReLU activation function for dense head layer to introduce non-linearity\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # Single output without sigmoid, BCE loss will apply sigmoid automatically\n",
    "        self.dense2 = nn.Linear(64, 1)\n",
    "        \n",
    "        # Step the schedule after each epoch\n",
    "        self.step_scheduler_after = \"epoch\"\n",
    "\n",
    "    def monitor_metrics(self, outputs, targets):\n",
    "        # Important: apply sigmoid function to output predictions and multiply by 100 to denormalize\n",
    "        outputs = sigmoid(outputs.cpu().detach().numpy()) * 100\n",
    "        \n",
    "        # Important: multiply targets by 100 to denormalize\n",
    "        targets = targets.cpu().detach().numpy() * 100\n",
    "        \n",
    "        # Calculate RMSE\n",
    "        rmse = metrics.mean_squared_error(targets, outputs, squared=False)\n",
    "        return {\"rmse\": rmse}\n",
    "\n",
    "    def fetch_scheduler(self):\n",
    "        # Cosine annealing scheduler\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            self.optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n",
    "        )\n",
    "        return scheduler\n",
    "\n",
    "    def fetch_optimizer(self):\n",
    "        # Adam optimizer\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "        return optimizer\n",
    "\n",
    "    def forward(self, image, features, targets=None):\n",
    "        # Forward pass through model\n",
    "        x = self.model(image)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.cat([x, features], dim=1)\n",
    "        x = self.dense1(x)\n",
    "        \n",
    "        # Important: pass through ReLU activation\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        # Output node\n",
    "        x = self.dense2(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            # Important: use binary cross entropy loss instead of mean squared error loss\n",
    "            loss = nn.BCEWithLogitsLoss()(x, targets.view(-1, 1))\n",
    "            \n",
    "            metrics = self.monitor_metrics(x, targets)\n",
    "            return x, loss, metrics\n",
    "        return x, 0, {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-28T01:58:12.241659Z",
     "iopub.status.busy": "2021-11-28T01:58:12.241200Z",
     "iopub.status.idle": "2021-11-28T01:58:12.315144Z",
     "shell.execute_reply": "2021-11-28T01:58:12.314495Z",
     "shell.execute_reply.started": "2021-11-28T01:58:12.241627Z"
    },
    "papermill": {
     "duration": 0.017735,
     "end_time": "2021-11-26T04:48:20.537990",
     "exception": false,
     "start_time": "2021-11-26T04:48:20.520255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load community-provided 5-fold preprocessed CSV file to dataframe\n",
    "df = pd.read_csv(\"../input/same-old-creating-folds/train_5folds.csv\")\n",
    "\n",
    "# Dataframes\n",
    "df_train = df[df.kfold != FOLD].reset_index(drop=True)\n",
    "df_valid = df[df.kfold == FOLD].reset_index(drop=True)\n",
    "\n",
    "# Image paths\n",
    "train_image_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_train[\"Id\"].values]\n",
    "valid_image_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_valid[\"Id\"].values]\n",
    "\n",
    "# Dense features (photo metadata)\n",
    "photo_metadata = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n",
    "train_dense_features = df_train[photo_metadata].values\n",
    "valid_dense_features = df_valid[photo_metadata].values\n",
    "\n",
    "# Targets (Pawpularity scores)\n",
    "train_targets = df_train[\"Pawpularity\"].values\n",
    "valid_targets = df_valid[\"Pawpularity\"].values\n",
    "\n",
    "# Augmentations: always resize and normalize, hue/saturation and brightness for train set only\n",
    "train_aug = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(IMAGE_SIZE, IMAGE_SIZE, p=1),\n",
    "        albumentations.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "        albumentations.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "        albumentations.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "            max_pixel_value=255.0,\n",
    "            p=1.0,\n",
    "        ),\n",
    "    ],\n",
    "    p=1.0,\n",
    ")\n",
    "valid_aug = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(IMAGE_SIZE, IMAGE_SIZE, p=1),\n",
    "        albumentations.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "            max_pixel_value=255.0,\n",
    "            p=1.0,\n",
    "        ),\n",
    "    ],\n",
    "    p=1.0,\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CustomDataset(\n",
    "    image_paths=train_image_paths,\n",
    "    dense_features=train_dense_features,\n",
    "    targets=train_targets,\n",
    "    augmentations=train_aug,\n",
    ")\n",
    "valid_dataset = CustomDataset(\n",
    "    image_paths=valid_image_paths,\n",
    "    dense_features=valid_dense_features,\n",
    "    targets=valid_targets,\n",
    "    augmentations=valid_aug,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-28T01:58:12.316789Z",
     "iopub.status.busy": "2021-11-28T01:58:12.316344Z",
     "iopub.status.idle": "2021-11-28T02:20:04.576858Z",
     "shell.execute_reply": "2021-11-28T02:20:04.575964Z",
     "shell.execute_reply.started": "2021-11-28T01:58:12.316756Z"
    },
    "papermill": {
     "duration": 7769.492983,
     "end_time": "2021-11-26T06:57:50.039181",
     "exception": false,
     "start_time": "2021-11-26T04:48:20.546198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22kto1k.pth\" to /root/.cache/torch/hub/checkpoints/swin_large_patch4_window12_384_22kto1k.pth\n",
      "100%|██████████| 992/992 [19:36<00:00,  1.19s/it, loss=0.665, rmse=19.6, stage=train]\n",
      "100%|██████████| 124/124 [01:45<00:00,  1.18it/s, loss=0.663, rmse=20.1, stage=valid]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score improved (inf --> 20.12838645135203). Saving model!\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = CustomModel()\n",
    "\n",
    "# Early stopping after 3 epochs of no validation RMSE improvement\n",
    "es = EarlyStopping(\n",
    "    monitor=\"valid_rmse\",\n",
    "    model_path=f\"model_f{FOLD}.bin\",\n",
    "    patience=3,\n",
    "    mode=\"min\",\n",
    "    save_weights_only=True,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    valid_dataset=valid_dataset,\n",
    "    train_bs=8,\n",
    "    valid_bs=16,\n",
    "    device=\"cuda\",\n",
    "    epochs=1,\n",
    "    callbacks=[es],\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-28T02:23:48.782874Z",
     "iopub.status.busy": "2021-11-28T02:23:48.782523Z",
     "iopub.status.idle": "2021-11-28T02:23:48.805076Z",
     "shell.execute_reply": "2021-11-28T02:23:48.804198Z",
     "shell.execute_reply.started": "2021-11-28T02:23:48.782835Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomInferenceModel(tez.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(\"swin_large_patch4_window12_384\", pretrained=False, in_chans=3)\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, 128)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.Linear(140, 64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, image, features, targets=None):\n",
    "        x = self.model(image)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.cat([x, features], dim=1)\n",
    "        x = self.dense1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x, 0, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-28T02:23:51.690061Z",
     "iopub.status.busy": "2021-11-28T02:23:51.689797Z",
     "iopub.status.idle": "2021-11-28T02:24:54.249916Z",
     "shell.execute_reply": "2021-11-28T02:24:54.248735Z",
     "shell.execute_reply.started": "2021-11-28T02:23:51.690032Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "1it [00:00,  1.68it/s]00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s, stage=test]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.56it/s, stage=test]\u001b[A\n",
      "1it [00:00,  1.53it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00,  1.89it/s]00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s, stage=test]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.68it/s, stage=test]\u001b[A\n",
      "1it [00:00,  1.63it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00,  1.93it/s]00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s, stage=test]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.76it/s, stage=test]\u001b[A\n",
      "1it [00:00,  1.72it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00,  1.88it/s]00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s, stage=test]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.73it/s, stage=test]\u001b[A\n",
      "1it [00:00,  1.68it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00,  1.92it/s]00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s, stage=test]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.74it/s, stage=test]\u001b[A\n",
      "1it [00:00,  1.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create test dataset\n",
    "df_test = pd.read_csv(\"../input/petfinder-pawpularity-score/test.csv\")\n",
    "test_image_paths = [f\"../input/petfinder-pawpularity-score/test/{x}.jpg\" for x in df_test[\"Id\"].values]\n",
    "test_dense_features = df_test[photo_metadata].values\n",
    "test_targets = np.ones(len(test_image_paths))\n",
    "test_aug = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(IMAGE_SIZE, IMAGE_SIZE, p=1),\n",
    "        albumentations.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "            max_pixel_value=255.0,\n",
    "            p=1.0,\n",
    "        ),\n",
    "    ],\n",
    "    p=1.0,\n",
    ")\n",
    "test_dataset = CustomDataset(\n",
    "    image_paths=test_image_paths,\n",
    "    dense_features=test_dense_features,\n",
    "    targets=test_targets,\n",
    "    augmentations=test_aug,\n",
    ")\n",
    "\n",
    "# Get predictions for all 5 folds\n",
    "all_fold_preds = []\n",
    "for fold in range(5):\n",
    "    # Load model for fold\n",
    "    model = CustomInferenceModel()\n",
    "    model.load(f\"../input/bce-20-epochs/model_f{fold}.bin\", device=\"cuda\", weights_only=True)\n",
    "\n",
    "    # Predict test set\n",
    "    test_preds = model.predict(test_dataset, batch_size=16, n_jobs=-1)\n",
    "\n",
    "    cur_fold_preds = []\n",
    "    for preds in tqdm(test_preds):\n",
    "        # Denormalize\n",
    "        preds = sigmoid(preds) * 100    \n",
    "        \n",
    "        # Convert to list\n",
    "        preds = preds.ravel().tolist()\n",
    "        \n",
    "        # Add to current fold list\n",
    "        cur_fold_preds.extend(preds)\n",
    "    \n",
    "    # Add current fold list to all folds list\n",
    "    all_fold_preds.append(cur_fold_preds)\n",
    "\n",
    "# Final prediction is the average of all folds\n",
    "df_test[\"Pawpularity\"] = np.mean(np.column_stack(all_fold_preds), axis=1)\n",
    "df_test = df_test[[\"Id\", \"Pawpularity\"]]\n",
    "df_test.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-28T02:24:59.630075Z",
     "iopub.status.busy": "2021-11-28T02:24:59.629324Z",
     "iopub.status.idle": "2021-11-28T02:24:59.650877Z",
     "shell.execute_reply": "2021-11-28T02:24:59.649957Z",
     "shell.execute_reply.started": "2021-11-28T02:24:59.630032Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4128bae22183829d2b5fea10effdb0c3</td>\n",
       "      <td>40.683147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43a2262d7738e3d420d453815151079e</td>\n",
       "      <td>41.558900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e429cead1848a298432a0acad014c9d</td>\n",
       "      <td>40.380956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80bc3ccafcc51b66303c2c263aa38486</td>\n",
       "      <td>40.515140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8f49844c382931444e68dffbe20228f4</td>\n",
       "      <td>40.567381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Pawpularity\n",
       "0  4128bae22183829d2b5fea10effdb0c3    40.683147\n",
       "1  43a2262d7738e3d420d453815151079e    41.558900\n",
       "2  4e429cead1848a298432a0acad014c9d    40.380956\n",
       "3  80bc3ccafcc51b66303c2c263aa38486    40.515140\n",
       "4  8f49844c382931444e68dffbe20228f4    40.567381"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
